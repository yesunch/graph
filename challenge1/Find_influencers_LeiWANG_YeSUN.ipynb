{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "# https://networkx.github.io/documentation/stable/reference/index.html\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pylab\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the graph\n",
    "# The graph is an extraction from LinkedIn Social Network\n",
    "G = nx.read_gexf(\"/Users/yesun/Documents/学习/IMT/graph/challenge1/mediumLinkedin.gexf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration of the graph : relational data understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: Graph\n",
      "Number of nodes: 811\n",
      "Number of edges: 1597\n",
      "Average degree:   3.9383\n"
     ]
    }
   ],
   "source": [
    "# networkx short summary of information for the graph g\n",
    "print(nx.info(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "811"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.number_of_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1597"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.number_of_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_e = pd.read_csv('/Users/yesun/Documents/学习/IMT/graph/challenge1/groundtruth/employer.csv', sep='\\t', header='infer')\n",
    "df_loc = pd.read_csv('/Users/yesun/Documents/学习/IMT/graph/challenge1/groundtruth/location.csv', sep='\\t', header='infer')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our part 1\n",
    "## calculate sum of edges weights for each node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U11575: 2\n",
      "U27460: 4\n",
      "U7202: 5\n",
      "U15267: 7\n",
      "U24045: 16\n"
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "\n",
    "# use class Node to represent each node with its weight. The weight is the sum of weight of all his edges \n",
    "class Node:\n",
    "    def __init__(self, name, weight):\n",
    "        self.name = name\n",
    "        self.weight = weight\n",
    "    def get_name(self):\n",
    "        return self.name\n",
    "    def get_weight(self):\n",
    "        return self.weight\n",
    "\n",
    "nodes = G.nodes()\n",
    "\n",
    "# save the neighbors of each node in a dict<node, list<node>>\n",
    "neighbor_dict = {}\n",
    "\n",
    "\n",
    "\n",
    "# get node and it's neighbors, save them in a dict\n",
    "for node in nodes:\n",
    "    # only process people who live in san francisco bay area\n",
    "    if df_loc[(df_loc['name'] == node)]['location'].any() == 'san francisco bay area':\n",
    "        neighbors = G.neighbors(node)\n",
    "        neighbor_list = []\n",
    "        for neighbor in neighbors:\n",
    "            neighbor_list.append(neighbor)\n",
    "        neighbor_dict[node] = neighbor_list\n",
    "        \n",
    "# use size fixed queue to save 5 persons with maximum weight\n",
    "deq = deque(maxlen=5)\n",
    "\n",
    "# calculate weight of each node, update the queue\n",
    "for node,neighbors in neighbor_dict.items():\n",
    "    # get employers of each node\n",
    "    node_attrs = df_e[(df_e['name'] == node)]['employer'].head()\n",
    "    sum_weight = 0\n",
    "    for neighbor in neighbors:\n",
    "        # get employers of this node's neighbors\n",
    "        neighbor_attrs = df_e[(df_e['name'] == neighbor)]['employer'].head()\n",
    "        # find the common employers of these two nodes\n",
    "        common_attrs = same_elem(node_attrs, neighbor_attrs)\n",
    "        # update the sum of weight of this node\n",
    "        sum_weight += len(common_attrs)\n",
    "        \n",
    "    # update the queue\n",
    "    if(len(deq) == 0 or sum_weight > deq[-1].get_weight()):\n",
    "        this_node = Node(node, sum_weight)\n",
    "        deq.append(this_node)\n",
    "    #print(str(node) +\" # \"+ df_loc[(df_loc['name'] == node)]['location']+\" # sum # \"+str(sum_weight))\n",
    "\n",
    "# print the names of the 5 people choosed\n",
    "for w in deq:\n",
    "    print (str(w.get_name()) + \": \"+str(w.get_weight()))\n",
    "\n",
    "    \n",
    "    \n",
    "def same_elem(list1, list2):\n",
    "    set1 = set(list1)\n",
    "    set2 = set(list2)\n",
    "    iset = set1.intersection(set2)\n",
    "    return list(iset)\n",
    "\n",
    "def is_in_sanfransicobay(node):\n",
    "    if(df_loc[(df_loc['name'] == node)]['location'] == 'san francisco bay area'):\n",
    "        return true\n",
    "    return false\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find inluencers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The different types of influencers are...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reformulate the problem and bring your solution here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
